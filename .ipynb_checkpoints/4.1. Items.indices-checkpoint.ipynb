{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:300%;font-family:verdana;color:navy;\">LECCIÓN 4.1. </h1>\n",
    "<h1 style=\"font-size:150%;font-family:verdana;color:navy;\">Índices de los ítems</h1>\n",
    "    \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Antes de comenzar a explicar paso por paso cómo se analizan los ítems de un test con el programa R cabe plantearse una pregunta clave: __¿para qué sirve dicho análisis?__ Fácil; es muy importante analizar los ítems de un test para detectar cuáles de ellos mejoran la fiabilidad de la prueba y cuáles la empeoran (ítems que habrá que eliminar). La TCT, aunque más centrada en las puntuaciones totales del test, también desarrolló un conjunto de procedimientos para el análisis de los items, dado que la calidad de la puntuación total depende de la de los ítems. \n",
    "\n",
    "\n",
    "## ¿Qué aspectos de nuestros ítems vamos a analizar?\n",
    "\n",
    "Para descubrir las propiedades estadísticas que nos permitan saber qué ítems son esenciales en nuestro test y de cuáles conviene prescindir, la TCT nos recomienda calcular dos estadísticos fundamentales: __índice de dificultad__ e __índice de discriminación__. Asimismo, es fundamental analizar si los ítems que hemos construido están __sesgados__ o no (ya veremos qué significa exactamente este término en el apartado correspondiente pero para que te hagas una idea, si en un test de inteligencia las mujeres obtienen puntuaciones muy bajas y los hombres muy altas...¡Alerta, alerta! Posible sesgo a la vista). Finalmente, en esta práctica hablaremos sobre las distintas __escalas__ en las que se pueden expresar las puntuaciones de los test para que todos (o la mayoría) podamos entenderlas. Un menú tentador, ¿verdad? Pero bueno, como dijo Jack el destripador, vamos por partes.\n",
    "\n",
    "## Estadísticos de los ítems\n",
    "\n",
    "Las propiedades de los items pueden cuantificarse mediante algunos índices estadísticos. A lo largo de la historia de la Psicometría se han desarrollado muchos índices con tal fin pero Castellanos es buena persona y solo te hará aprender dos de ellos (los más utilizados): __índice de dificultad__ e __índice de discriminación__.\n",
    "\n",
    "### Índice de dificultad\n",
    "\n",
    "Este índice (es una proporción) nos da información acerca de lo difícil/fácil que es un ítem (en caso de que nuestra prueba no contenga ítems fáciles o difíciles como ocurre, por ejemplo, en un test de personalidad, hablaríamos entonces de ítems cuyas respuestas son más o menos comunes). Al contrario de lo que pudiera parecer, a mayor índice de dificultad, mayor facilidad del ítem.\n",
    "\n",
    "$$ P_i=\\frac{A_i}{N}$$\n",
    "\n",
    "Donde $A_i$ es el número de aciertos del item y $N$ el número de personas que han contestado al test.\n",
    "\n",
    "### Índice de discriminación\n",
    "\n",
    "Este índice (que es una correlación) indica la relación que existe entre un ítem y la puntuación total del test (puntuación empírica del sujeto). Así, decimos que un ítem tiene un buen nivel de discriminación si es capaz de diferenciar a los sujetos que obtienen puntuaciones elevadas en el test de aquellos que no. Al ser una correlación la representamos como:\n",
    "\n",
    "$$\\rho_{xi}$$\n",
    "\n",
    "Donde en el subíndice el símbolo $x$ representa la puntuación total o empírica del test y el subíndice $i$ indica el item concreto que estoy calculando\n",
    "\n",
    "Como has visto en teoría existen diversos procedimientos para calcular este índice de discriminación dependiendo de si el item es dicotómico y si la puntuación total lo es. El procedimiento que vamos a mostrar con R es el que se utiliza en el caso más común: el item es dicotómico y la puntuación total es cuantitativa continua.\n",
    "\n",
    "\n",
    "### ¿Cómo calculamos ambos índices con R Studio?\n",
    "\n",
    "He aquí la pregunta del millón. ¿Preparado/a? __¡Vamos a por ello, valiente!__ Como siempre empezamos por cargar unos datos de ejemplo, el fichero llamado _items.csv_ y llamarlos __datos__.\n",
    "\n",
    "```R\n",
    "    datos <- read.csv(file=\"datos/items.csv\", header=TRUE, sep=\";\", dec =\",\")\n",
    "    datos\n",
    "```  \n",
    "\n",
    "__Ejercicio 1:__ Importa el fichero _items.csv_ que está en la carpeta _datos_ y al objeto donde lo vas a guardar llámalo __datos__, después visualízalo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce aquí tu código (para ejecutarlo pulsa Ctr+Enter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si lo has cargado correctamente verás que contiene las siguientes variables:\n",
    "\n",
    "* Sexo: con los valores hombre y mujer\n",
    "* V1 hasta V50: los 50 items dicotómicos que componen mi test de inteligencia\n",
    "* x: la puntuación empírica que es la suma de los 50 items\n",
    "\n",
    "Así, el primer sujeto es un hombre y tiene una puntuación empírica de 44 porque ha acertado 44 de los 50 items del test.\n",
    "\n",
    "Para poder utilizar las funciones que necesitamos debes importar la librería __psych__. Ya lo has hecho otras veces así que no lo vuelvo a explicar.\n",
    "\n",
    "__Ejercicio 2:__ Carga la librería __psych__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce aquí el código (para ejecutarlo pulsa Ctr+Enter) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ¡A por los índices!\n",
    "\n",
    "Perfecto. Ahora, para que nos resulte más fácil trabajar con la cantidad de información que tenemos, vamos a agrupar las 50 variables (de la V1 a la V50) en un solo conjunto de datos al que llamaremos _items_. ¿Cómo? Ejecuta el siguiente comando que ya fue explicado en las lecciones del tema 1: \n",
    "\n",
    "```R\n",
    "    items <- subset(datos, select=c(V1:V50))\n",
    "```  \n",
    "\n",
    "El data frame que hemos llamado datos contiene tanto los items como otras variables (el sexo y la puntuación empírica) pero para poder usar las funciones que usaremos a continuación solo podemos pasarle los items. La solución anterior es cómoda para eso ya que ahora __items__ solo contiene los items.\n",
    "\n",
    "__Recuerda__ que en la sintaxis ponemos _datos_ porque es el nombre de nuestro objeto que contiene los datos; si tu base de datos tiene otro nombre, pon el que corresponda. __Sin embargo__, a partir de este momento y para los comandos siguientes, nos referiremos al conjunto de datos con el que vamos a trabajar utilizando el término _items_, que para eso lo acabamos de crear con ese nombre.\n",
    "\n",
    "Adelante, prueba a hacerlo tú.\n",
    "\n",
    "__Ejercicio 3:__ Crea un nuevo data frame que contengo solamente los items y llámalo __items__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce aquí tu código (para ejecutarlo pulsa Ctr+Enter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, un paso previo a conocer los índices de dificultad y discriminación de los ítems de nuestro maravilloso test es el cálculo de alpha de Cronbach (fiabilidad). ¿Para qué necesitamos conocer el valor de alpha? ¡Más adelante lo sabrás! __Importante__: al analizar los ítems de un test, nos interesa que R genere una gran cantidad de decimales tanto al estimar alpha como al calcular ambos índices (si te vuelves a preguntar \"¿por qué?\" me temo que tendrás que esperar un poco para conocer la respuesta). Ahora bien, ¿cómo conseguimos dichos decimales? Pues pidiéndoselo amablemente a R:\n",
    "\n",
    "```R\n",
    "    alpha(items)$total\n",
    "``` \n",
    "\n",
    "> Aquí se ha puesto la sintaxis resumida, todo junto, pero es exactamente lo mismo que hacer\n",
    "```R\n",
    "    a <- alpha(items)\n",
    "    a$total\n",
    "``` \n",
    "\n",
    "¿Quieres intentarlo?\n",
    "\n",
    "__Ejercicio 4:__ calcula alpha con el data frame llamado __items__ y pide que te de todos los decimales posibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce aquí tu código (para ejecutarlo pulsa Ctr+Enter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ejecutarlo habrás obtenido una salida como esta\n",
    "\n",
    "```\n",
    "raw_alpha\tstd.alpha\tG6(smc)\taverage_r\tS/N\tase\tmean\tsd\n",
    "0.878522\t0.8757964\t0.8885309\t0.1235957\t7.051295\t0.007788031\t0.6390678\t0.1523906\n",
    "\n",
    "\n",
    "``` \n",
    "\n",
    "He aquí otra pregunta del millón: ¿cuál de todas las cifras que aparecen es nuestro famoso alpha de Cronbach? Fácil: alpha es el número que se encuentra en la columna _raw-alpha_: 0.8785\n",
    "\n",
    "¡Estupendo! Dejemos al gran alpha de lado (más tarde lo volveremos a retomar) y vamos a por nuestros índices, que para eso hemos venido, ¿o no? Pues bien, no creo que te sorprenda pero, de nuevo, la clave para conseguir dar con ellos es un maravilloso comando:\n",
    "\n",
    "```R\n",
    "    alpha(items)$item.stats\n",
    "``` \n",
    "\n",
    "__Ejercicio 5:__ calcula los estadísticos descriptivos de los items con todos sus decimales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce aquí tu código (para ejecutarlo pulsa Ctr+Enter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Has estado a punto de caerte de la silla al ver tu pantalla llena de números, ¿verdad? Pues tranquilo/a, que es más fácil de lo que parece. El índice de dificultad (sin corrección del azar) de cada uno de los ítems es la cifra que aparece en la columna _mean_:\n",
    "\n",
    "__Por ejemplo:__ el índice de dificultad del ítem 5 (V5) es 0.9449153. Este número nos indica que se trata de un ítem bastante sencillo puesto que casi el 95% de las personas que realizan el test lo aciertan.\n",
    "\n",
    "\"Profe, profe, ¿y el índice de discriminación?\" ¡Buena pregunta! Este índice se encuentra representado en las columnas _r.cor_ y _r.drop_; me explico: _r.cor_ recoge los índices de discriminación __sin corrección__ de solapamiento y _r.drop_ los índices de discriminación __con corrección__ de solapamiento. \"¿Qué es esto del solapamiento?\", te estarás preguntando. Ten en cuenta que estamos calculando la correlación de un ítem con la puntuación total del test, por lo que para que esta correlación sea certera, se ha de eliminar el ítem correspondiente de su cálculo. Por ejemplo para el item 5 (V5) el su índice de discriminación sin corrección es 0.2346... y con la corrección es 0.2041... (normalmente más pequeño sin corrección).\n",
    "\n",
    "Hasta aquí todo perfecto, ¿verdad?. Ahora bien, si recuerdas, al principio de la práctica se exponía que el objetivo esencial del análisis de ítems de un test era detectar cuáles de ellos mejoran la fiabilidad de la prueba y cuáles la empeoran, ¿correcto? Pues bien, conociendo solo sus índices de dificultad y discriminación no podemos saber ese dato. ¿Qué hacemos entonces? Sí, es lo que estás pensando... ¡Hay que introducir un nuevo comando! Gracias a él sabremos cuál sería la fiabilidad de la prueba si el ítem escogido fuera eliminado:\n",
    "\n",
    "```R\n",
    "    alpha(items)$alpha.drop\n",
    "``` \n",
    "¡Corre! ¡Ejecútalo y tendrás en tu poder esa valiosa información!\n",
    "\n",
    "__Ejercicio 6:__ calcula los valores de alpha si el item es eliminado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce aquí tu código (para ejecutarlo pulsa Ctr+Enter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La columna a la que hay que prestar atención es aquella encabezada por _raw alpha_. Para entender mejor el significado de estas cifras, pongamos un __ejemplo__, ¿de acuerdo? Escogemos el ítem 1 (V1) y nos fijamos en el valor de su _raw alpha_ (fiabilidad de la prueba si el ítem 17 fuera eliminado): 0.8779273. Si recordamos, nuestro alpha de Cronbach (anteriormente calculado) es 0.878522. Si eliminásemos ese item la fiabilidad del test disminuiría, porque pasaría de 0.878522 a 0.8779273. Es verdad que disminuiría muy poco, pero lo haría, por lo tanto el sentido común nos dice que __es mejor no eliminar el item V1__. La misma comparación haríamos con los restantes 49 items, comprobando uno a uno si al ser eliminado la fiabilidad aumentaría (en cuyo caso sería recomendable eliminarlo). En nuestros datos no tenemos ningún item que deba ser eliminado por este motivo.\n",
    "\n",
    "La comparación anterior puede hacerse un poco tediosa, pero aprovechando que R es un lenguaje de programación podemos hacerla más cómoda si usamos un poco de sintaxis\n",
    "\n",
    "```\n",
    "    data.frame(item=1:ncol(items), diferencia=alpha(items)$alpha.drop$raw_alpha-alpha(items)$total$raw_alpha)\n",
    "```\n",
    "\n",
    "Esta sintaxis es bastante sencilla pero excede un poco los objetivos del curso, ahora simplemente cópiala y úsala. Lo que hacemos es restar los dos valores, el alfa si el item es eliminado con el alfa del test. Si al eliminar el item la fiabilidad mejora debe darnos un valor positivo, y si empeora uno negativo. Buscando en la lista los valores positivos sabremos qué items deberíamos eliminar (en este caso ninguno).\n",
    "\n",
    "Llegados a este punto ya habrás dado respuesta a las dos cuestiones que se han planteado al principio, ¿verdad?:\n",
    "\n",
    "-  ¿Por qué hay que calcular alpha de Cronbach?: porque sin él no podríamos saber si un ítem suma o resta fiabilidad a la prueba (¿con qué compararíamos los valores de _raw alpha_ entonces?)\n",
    "-  ¿Para qué queremos tantísimos decimales?: porque los necesitamos para afinar la comparación anterior (hemos de ser muy minuciosos en el análisis).\n",
    "\n",
    "__Ejercicio 7:__ Usa la sintaxis para comparar si alpha cambia cuando se elimina cada uno de los ítems del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce aquí tu código (para ejecutarlo pulsa Ctr+Enter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Soluciones a los ejercicios:\n",
    "***\n",
    " \n",
    "\n",
    "<details>\n",
    "<summary> Click para ver las soluciones </summary>\n",
    "\n",
    "__Ejercicio 1:__\n",
    "```\n",
    "    datos <- read.csv(file=\"datos/items.csv\", header=TRUE, sep=\";\", dec =\",\")\n",
    "    datos\n",
    "```\n",
    "\n",
    " __Ejercicio 2:__\n",
    "```R\n",
    "    library(psych)\n",
    "```\n",
    "\n",
    "__Ejercicio 3:__\n",
    "```R\n",
    "    items <- subset(datos, select=c(V1:V50))\n",
    "    items \n",
    "```\n",
    "\n",
    "__Ejercicio 4:__\n",
    "```\n",
    "    alpha(items)$total\n",
    "```\n",
    "\n",
    "__Ejercicio 5:__\n",
    "```R\n",
    "    alpha(items)$item.stats\n",
    "```\n",
    "\n",
    "__Ejercicio 6:__\n",
    "```\n",
    "    alpha(items)$alpha.drop\n",
    "```\n",
    "\n",
    "__Ejercicio 7:__\n",
    "```\n",
    "    data.frame(item=1:ncol(items), diferencia=alpha(items)$alpha.drop$raw_alpha-alpha(items)$total$raw_alpha)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<div align=\"right\">\n",
    "  Enero de 2020 |\n",
    "  <a href=\"autores.ipynb\"> AUTORES <a>\n",
    "</div> \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
