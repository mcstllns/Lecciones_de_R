{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:300%;font-family:verdana;color:navy;\">LECCIÓN 4.2. </h1>\n",
    "<h1 style=\"font-size:150%;font-family:verdana;color:navy;\">Puntuaciones de los test</h1>\n",
    "    \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. La interpretación de las puntuaciones: escalas, normas y equivalencias\n",
    "\n",
    "Las puntuaciones de los tests suelen ser difíciles de interpretar, especialmente por la gran variedad de escalas en las que se expresan. De hecho, algunos autores opinan que existen casi tantos tipos de escalas como test se han construido. ¿Te imaginas qué caóticos serían los cálculos, las interpretaciones, las comparaciones entre puntuaciones de diferentes test, etc. si no hubiera una solución a este problema? Por suerte para nosotros, hace años que grandes mentes se las ingeniaron para subsanar dicho contratiempo. ¿Cómo? \"Traduciendo\" las diferentes puntuaciones a un \"lenguaje común\"; es decir, construyendo baremos que comparen la puntuación de un sujeto con las de su grupo de referencia de una forma estandarizada. Para llevar a cabo esta \"traducción\" se han diseñado dos grandes grupos de técnicas: las __transformaciones lineales__ y las __transformaciones no lineales__. Veamos de qué trata cada una y cómo se calculan.\n",
    "\n",
    "> Al igual que en el resto de lecciones se recomienda al alumno que lea esto una vez que haya leído y entendido las lecturas de teoría.\n",
    "\n",
    "Antes de empezar a explicar nada vamos a cargar el fichero de datos que vamos a utilizar en esta práctica, se llama _items.csv_ y lo cargaremos de la misma forma que en otras lecciones.\n",
    "\n",
    "__Ejercicio:__ Importa el fichero _items.csv_ y al objeto donde lo vas a guardar llámalo __datos__, después visualízalo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce aquí el código (para ejecutarlo pulsa Ctr+Enter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si lo has cargado correctamente verás que contiene las siguientes variables:\n",
    "\n",
    "* Sexo: con los valores hombre y mujer\n",
    "* V1 hasta V50: los 50 items dicotómicos que componen mi test de inteligencia\n",
    "* x: la puntuación empírica que es la suma de los 50 items\n",
    "\n",
    "Así, el primer sujeto es un hombre y tiene una puntuación empírica de 44 porque ha acertado 44 de los 50 items del test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Transformaciones lineales\n",
    "\n",
    "Estas transformaciones no alteran la forma de la distribución original de las puntuaciones; si la distribución original era normal, permanece así después de la transformación; si por el contrario era sesgada positiva o negativamente, platicúrtica o multimodal, estas características también se mantienen después de la transformación.\n",
    "\n",
    "## 2.1. Puntuaciones estandarizadas o típicas (Zx)\n",
    "\n",
    "La transformación lineal directa es el más simple de todos los métodos de \"traducción\" (a partir de ahora, utilizaremos un término más adecuado/técnico para referirnos a dicha \"traducción\": escalamiento de puntuaciones, ¿vale?). Así, el test se administra a un grupo de sujetos representativo de la población para la que está destinado. Una vez aplicado el test a este grupo, se calculan su media y su desviación típica y se calculan las puntuaciones típicas o estandarizadas, con media 0 y desviación típica 1, que tienen un significado universal. La conversión a puntuaciones típicas supone un cambio de origen de la escala (la media) y de unidad de medida, ya que las puntuaciones representan distancias de la media en unidades de desviación típica; por ejemplo, una puntuación típica de 1 expresa que el sujeto se diferencia de la media (origen) en una desviación típica (unidad de medida). La fórmula para calcular una desviación típica es:\n",
    "\n",
    "\n",
    "$$ Z_x = \\frac{X - \\overline{X}}{S_x }$$\n",
    "\n",
    "¿Cómo calculamos entonces puntuaciones típicas? Lo primero que necesitamos es la media y desviación típica de la variable x, si recordamos de las primeras lecciones estas las podíamos calcular con las funciones _mean()_ y _sd()_. Las vamos a guardar en las variables _media_ y _destip_ respectivamente.\n",
    "\n",
    "\n",
    "```\n",
    "    media <- mean(datos$x)\n",
    "    destip <- sd(datos$x) \n",
    "``` \n",
    "\n",
    "\n",
    "Y si queremos calcular la típica para el primer sujeto que ha obtenido una empírica de 44 solo tenemos que utilizar la fórmula\n",
    "\n",
    "\n",
    "```R\n",
    "    (44 - media) / destip\n",
    "``` \n",
    "\n",
    "Y si lo queremos calcular para todos los sujetos de la muestra lo que podemos hacer es __crear una nueva variable__ dentro del data frame datos que se llame por ejemplo _ZX_ usando la misma fórmula:\n",
    "\n",
    "```\n",
    "    datos$ZX <- (datos$x - media) / destip\n",
    "``` \n",
    "\n",
    "Si visualizas tu conjunto de datos verás que una nueva variable ha aparecido al final\n",
    "\n",
    "\n",
    "```R\n",
    "    datos\n",
    "``` \n",
    "\n",
    "__Ejercicio 2:__ Crea una nueva variable llamada ZX que contenga las puntuaciones típicas de cada sujeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce aquí el código (para ejecutarlo pulsa Ctr+Enter) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si lo has calculado correctamente al primer sujeto le habrás asignado una $Z_x = 1.58$ que se interpreta como que ese sujeto se encuentra 1.58 desviaciones típicas por encima de la media."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Puntuaciones típicas derivadas (ZD)\n",
    "\n",
    "Una vez realizada la transformación anterior, las puntuaciones pueden transformarse de nuevo linealmente a una nueva escala con media (origen) y desviación típica (unidad) fijadas por el constructor del test. Y te preguntarás... ¿para qué querría el constructor de un test rizar tanto el rizo? Recuerda que, tal y como has visto en teoría, trabajar con puntuaciones típicas negativas es complicado porque suenan verdaderamente mal, así que si podemos \"maquillarlas\" para que queden más bonitas, mejor que mejor (con este objetivo surgen las puntuaciones típicas derivadas). Para lograr la transformación que buscamos habría que aplicar la siguiente función: \n",
    "\n",
    "$$ Z_D = \\overline{X}^t + S_x^t \\thinspace Z_x $$\n",
    "\n",
    "Con la \"t\" encima de la media ($\\overline{X}^t$) y de la desviación típica ($S_x^t$) estamos indicando que ambas son elegidas arbitrariamente para la transformación. ¿Te apetece que calculemos la puntuación típica derivada para nuestros datos? ¡Pues no se hable más y vamos a por ello! A patir de las puntuaciones típicas que hemos calculado antes vamos a crear una nueva variable que tenga una media de 100 y una desviación típica de 10.\n",
    "\n",
    "```\n",
    "    datos$ZD <- 100 + 10 * datos$ZX\n",
    "``` \n",
    "\n",
    "__Ejercicio 3:__ Crea una nueva variable llamada ZD que sea una transformación tipica derivada con media 100 y desviación típica 10\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce aquí el código (para ejecutarlo pulsa Ctr+Enter) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si lo has resuelto bien el primer sujeto tendrá una típica derivada de 115.81\n",
    "\n",
    "> __Importante__: existen una serie de escalas derivadas de amplio uso con valores ya fijados para la media y desviación típica, como las puntuaciones T (50, 10) o el CI (100,15), entre otras. Es probable que Castellanos te haga calcular alguna de ellas, así que recuerda: simplemente debes sustituir en la fórmula anterior la media y desviación típica arbitrarias (las que te pida) de estas nuevas puntuaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 3. Transformaciones no lineales\n",
    "\n",
    "Para las puntuaciones de los tests también pueden establecerse transformaciones no lineales, conservando las propiedades de monotonía creciente (con el ejemplo de la primera transformación que te voy a presentar entenderás lo que quiero decir con esto). Este tipo de transformaciones alteran la forma de las distribuciones originales. Veámos cuáles son las más habituales:\n",
    "\n",
    "## 3.1. Rangos percentiles\n",
    "\n",
    "Sin duda, la ventaja principal del cálculo de percentiles es su facilidad. Ahora bien, los percentiles tienen un problema y es que, como se ha expuesto en el párrafo anterior, se trata de una escala no lineal. ¿Por qué esto es un inconveniente? Porque conociendo el percentil de dos personas en un test de inteligencia podemos saber quién de ellas es más \"lista\" pero no cuánto más. Te pongo un ejemplo con números para que lo entiendas mejor:\n",
    "\n",
    "-  Pepito se sitúa en el percentil 70.\n",
    "-  Menganito se sitúa en el percentil 50.\n",
    "\n",
    "¿Quiere esto decir que Pepito es más inteligente que Menganito? __Posiblemente__. ¿Veinte veces más? __Ni hablar__. Asimismo, ¿esos resultados significan que Pepito acertó 20 preguntas más que Menganito? __Rotundamente no__ (tampoco existe una relación lineal entre preguntas acertadas y percentiles).\n",
    "\n",
    "Si hasta aquí está todo claro, ¡procedamos a calcular percentiles! Imagínate, por ejemplo, que queremos saber, según los datos que tenemos en nuestro archivo, cuál es la puntuación empírica del test que corresponde al percentil 90 (es decir, la puntuación que obtiene una persona que saca un resultado superior al del 90% de la población). Fácil: \n",
    "\n",
    "```R\n",
    "    quantile(datos$x,(0.9)) \n",
    "``` \n",
    "\n",
    "Si queremos hacerlo un poco más completo y calcular más percetiles podemos modificar un poco la sintaxis como vimos en las primeras lecciones\n",
    "\n",
    "```R\n",
    "    quantile(datos$x,c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)) \n",
    "``` \n",
    "\n",
    "__A modo de aclaración__: la \"x\" del comando hace referencia a la puntuación empírica de los sujetos. ¿Ves qué sencillo? Venga, ahora calcula tú la puntuación empírica que corresponde al percentil 45 (seguro que lo bordas):\n",
    "\n",
    "__Ejercicio 4:__ Calcula la puntuación empìrica asociada con el percentil 45 y calcula todos los deciles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce aquí tu código (para ejecutarlo pulsa Ctr+Enter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si tu resultado es 31 para el percentil 45, ¡estás de enhorabuena! Veo que te has venido arriba así que, ¿te apetece que sigamos conociento qué más transformaciones no lineales se pueden usar? Pues dicho y hecho, amigo/a.\n",
    "\n",
    "Para hacerlo más útil vamos a guardar esta tabla que hemos creado en un data frame que voy a llamar __Tnolineal__ y que luego usaremos más adelante. Para ello puedo usar la siguiente sintaxis:\n",
    "\n",
    "```R\n",
    "    v <- seq(0,1,0.1) # creamos una secuencia con los percentiles que quiero calcular\n",
    "    Tnolineal <- data.frame(percentil=v*100, probabilidad=v, x = quantile(datos$x,v)) \n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "__Ejercicio 5:__ Crea el data frame Tnolineal según las instrucciones dadas y visualízalo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce aquí tu código (para ejecutarlo pulsa Ctr+Enter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fíjate que ahora tenemos tres columnas en el data frame: percentil, probabilidad y x. La interpretación es sencilla, el percentil 20 (tercera fila) cuya probabilidad es 0.20 tiene una puntuación empírica (x) asociada de 26.0.\n",
    "\n",
    "Para pasar de percentiles a probabilidades simplemente se divide entre 100 y a la inversa se multiplica por 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Puntuaciones típicas normalizadas (ZN)\n",
    "\n",
    "Un problema de las distribuciones de puntuaciones directas y sus transformaciones lineales que hemos calculado anteriormente es que dependen de ciertas características de los ítems particulares del test. Por ese motivo, suele ser conveniente transformar la escala a algún otro sistema de puntuaciones o de unidades independiente de dichas características. Asimismo, según varios autores, aunque no todas las distribuciones de los tests sean normales, es preferible normalizar las puntuaciones (es decir, ajustarlas a la curva normal o campana de Gauss que tantas veces has visto por ahí).\n",
    "\n",
    "Con todo lo anterior, reflexiona un momento. ¿De qué dos ingredientes constarán las puntuaciones típicas normalizadas? ¡Efectivamente! Estas transformaciones se calculan a partir de los __percentiles__ y __la distribución normal__. ¿Qué pasos hay que seguir para calcular ZN?\n",
    "\n",
    "1. Transformamos el percentil pertinente en una probabilidad (por ejemplo, percentil 50 -> p=0.5).\n",
    "2. Buscamos dicha probabilidad en la tabla correspondiente de la distribución normal y obtenemos su puntuación típica.\n",
    "\n",
    "__Súper-mega-híper-importante__: para poder calcular la puntuación típica normalizada, la variable que estemos analizando (inteligencia, en los ejemplos anteriores que hemos puesto) debe seguir una distribución normal. ¿Cómo comprobamos dicha normalidad? Pues tienes hasta tres opciones para elegir:\n",
    "\n",
    "1. Prueba de Kolmogorov-Smirnov\n",
    "2. Prueba de Shapiro-Wilk\n",
    "3. Prueba de bondad de ajuste de χ²\n",
    "\n",
    "Para no complicarlo demasiado, en nuestro ejemplo comprobaremos el supuesto de normalidad a través de la segunda opción: la prueba de Shapiro-Wilk. Su sintaxis:\n",
    "\n",
    "```R\n",
    "    shapiro.test(datos$x)\n",
    "``` \n",
    "__Ejercicio 6:__ Calcula con la prueba de Shapiro si las puntuaciones empíricas de nuestro test son normales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce aquí tu código (para ejecutarlo pulsa Ctr+Enter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué p-value has obtenido?, ¿0.001039? ¡Coooorrecto, entonces! ¿Y esto qué nos está queriendo decir? En un contraste sobre el supuesto de normalidad, la hipótesis nula ($H_0$) siempre es que nuestra variable __sí__ sigue una distribución normal en la población. Recuerda que para aceptar $H_0$, el p-value tiene que ser superior a 0.05. Como 0.001039 < 0.05, concluimos lo contrario: la variable analizada __no__ se ajusta a una distribución normal. \n",
    "\n",
    "Aunque la variable no se ajuste a la normal, y aunque algunos autores consideren que en ese caso no sería adecuado vamos a calcular las puntuaciones típicas normalizadas (ZN). Para ello vamos a crear una nueva variable en el data frame __Tnolineal__ que contenga la puntuación de la distribución normal asociada con cada percentil. Para ello usaremos la función _qnorm()_.\n",
    "\n",
    "Esta función te devuelve la Z asociada a una probabilidad concreta, por ejemplo, para saber que puntuación típica le correspondería a una probabilidad de 0.975 haría: qnorm(0.975) y obtendría un valor de 1.96. Otras Z conocidas por ser usadas siempre en estadística son:\n",
    "\n",
    "```R\n",
    "    qnorm(0.005) # obtengo -2.58\n",
    "    qnorm(0.025) # obtengo -1.96\n",
    "    qnorm(0.5)   # obtengo 0\n",
    "    qnorm(0.975) # obtengo +1.96\n",
    "    qnorm(0.995) # obtengo +2.58\n",
    "```\n",
    "\n",
    "Para calcularlo con todas las probabilidades de que tenemos en Tnolineal podemos usar la sintaxis:\n",
    "\n",
    "```\n",
    "    Tnolineal$ZN <- qnorm(Tnolineal$probabilidad)\n",
    "```\n",
    "\n",
    "__Ejercicio 7:__ Calcula las ZN para las probabilidades guardadas en Tnolineal y visualizalo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce aquí tu código (para ejecutarlo pulsa Ctr+Enter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y la forma de interpretar esta tabla es la siguiente: Alguien que haya obtenido un valor de 21 puntos en el test (segunda fila, con valor igual a 21) tiene asignada una puntación típica normalizada de -1.28 (ZN=-1.28).\n",
    "\n",
    "Como verás tanto la probabilida de 0 como la de 1 tienen una ZN igual a infinito (inf), es lógico ya que la distribución normal es asintótica y normalmente esos valores se omiten de las tablas finales de resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Puntuaciones típicas normalizadas derivadas (ZND)\n",
    "\n",
    "Las puntuaciones típicas normalizadas también pueden transformarse linealmente, como se ha hecho anteriormente con las típicas directas, fijando previamente la media y la desviación típica de la escala deseada.\n",
    "\n",
    "Entre las escalas normalizadas derivadas más comunes se encuentran la escala de estaninos o __eneatipos__ y la \"Standard Ten\", \"sten\" o __decatipos__ (seguro que en teoría has visto alguna más, pero nosotros nos quedamos con esas dos).\n",
    "\n",
    "##### Eneatipos #####\n",
    "\n",
    "Los eneatipos son un tipo de puntuaciones con media 5 y desviación típica de 2. Asimismo, __sus valores no pueden en ningún caso ser superiores a 9__ (si lo fueran, se redondearía dicho número). Cuidado con esto último porque se suele olvidar y muchos alumnos caen como moscas en este punto (no seas uno de ellos). Su fórmula es la siguiente:\n",
    "\n",
    "$$ EN=5+2ZN $$\n",
    " \n",
    "Podemos calcularlos para nuestra tabla de resultados no lineales igual que con las otras puntuaciones\n",
    "\n",
    "```\n",
    "    Tnolineal$EN <- 5 + 2 * Tnolineal$ZN\n",
    "```\n",
    "\n",
    "Es habitual presentar los eneatipos como números enteros sin decimales, esto puede solucionarse con la función _round()_ que permite redondear un número a la cantidad de decimales deseados (en este caso cero).\n",
    "\n",
    "```\n",
    "    Tnolineal$EN <- round(Tnolineal$EN, 0)\n",
    "```\n",
    "\n",
    "__Ejercicio 8:__ Calcula los eneatipos para la tabla Tnolineal y visualízala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce aquí las operaciones pertinentes (para ejecutarlo pulsa Ctr+Enter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decatipos #####\n",
    "\n",
    "Los decatipos son muy similares a los eneatipos aunque su valor máximo se sitúa en 10 y su media y desviación típica son 5,5 y 2, respectivamente. Si traducimos estos datos a una pequeña fórmula matemática, obtendríamos esta expresión:\n",
    "\n",
    "\n",
    "$$ DC=5.5+2ZN $$\n",
    " \n",
    "Podemos calcularlos para nuestra tabla de resultados no lineales igual que no las otras puntuaciones. Al igual que con los Eneatipos no se suelen dar los decimales.\n",
    "\n",
    "```\n",
    "    Tnolineal$DC <- 5.5 + 2 * Tnolineal$ZN\n",
    "    Tnolineal$DC <- round(Tnolineal$DC, 0)\n",
    "```\n",
    "\n",
    "¡Venga!, el último esfuerzo antes de caer exhausto: con los datos del apartado anterior.\n",
    "\n",
    "__Ejercicio 9:__ Calcula los decatipos para la tabla Tnolineal y visualízala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce aquí las operaciones pertinentes (para ejecutarlo pulsa Ctr+Enter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemos una tabla con todas las transformacione no lineales. Si por ejemplo alguien sacase una puntuación empírica de 35 en el test (x = 35) sabríamos inmediatamente que le correspondería una típica normalizada de 0.25 (ZN = 0.25), un Eneatipo de 6 (En=6) y un decatipo también de 6 (DC = 6).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Soluciones a los ejercicios:\n",
    "***\n",
    " \n",
    "\n",
    "<details>\n",
    "<summary> Click para ver las soluciones </summary>\n",
    "\n",
    "\n",
    "__Ejercicio 1:__\n",
    "```\n",
    "    datos <- read.csv(file=\"datos/items.csv\", header=TRUE, sep=\";\", dec =\",\")\n",
    "    datos\n",
    "```\n",
    "\n",
    " __Ejercicio 2:__\n",
    "```\n",
    "    media <- mean(datos$x)\n",
    "    destip <- sd(datos$x) \n",
    "    datos$ZX <- (datos$x - media) / destip\n",
    "    datos\n",
    "```\n",
    "\n",
    "__Ejercicio 3:__\n",
    "```\n",
    "    datos$ZD <- 100 + 10 * datos$ZX\n",
    "    datos\n",
    "```\n",
    "\n",
    "__Ejercicio 4:__\n",
    "```\n",
    "    quantile(datos$x,c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)) \n",
    "    quantile(datos$x,c(0.45)) \n",
    "```\n",
    "\n",
    "__Ejercicio 5:__\n",
    "```R\n",
    "    v <- seq(0,1,0.1) # creamos una secuencia con los percentiles que quiero calcular\n",
    "    v\n",
    "    Tnolineal <- data.frame(percentil=v*100, probabilidad=v, x = quantile(datos$x,v)) \n",
    "    Tnolineal\n",
    "```\n",
    "\n",
    "__Ejercicio 6:__\n",
    "```\n",
    "    shapiro.test(datos$x)\n",
    "```\n",
    "\n",
    "__Ejercicio 7:__\n",
    "```\n",
    "    Tnolineal$ZN <- qnorm(Tnolineal$probabilidad)\n",
    "    Tnolineal\n",
    "```\n",
    "__Ejercicio 8:__\n",
    "```\n",
    "    Tnolineal$EN <- 5 + 2 * Tnolineal$ZN\n",
    "    Tnolineal$EN <- round(Tnolineal$EN, 0)\n",
    "\n",
    "    Tnolineal\n",
    "```\n",
    "__Ejercicio 9:__\n",
    "```\n",
    "    Tnolineal$DC <- 5 + 2 * Tnolineal$ZN\n",
    "    Tnolineal$DC <- round(Tnolineal$DC, 0)\n",
    "    Tnolineal\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<div align=\"right\">\n",
    "  Enero de 2020 |\n",
    "  <a href=\"autores.html\"> AUTORES <a>\n",
    "</div> \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
