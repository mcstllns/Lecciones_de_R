{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:300%;font-family:verdana;color:navy;\">LECCIÓN 3.1. </h1>\n",
    "<h1 style=\"font-size:150%;font-family:verdana;color:navy;\">FIABILIDAD. Acuerdo entre jueces</h1>\n",
    "    \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Hola! Hoy vamos a realizar una de las practicas más importantes de todo el curso (su importancia es proporcional a su longitud, disculpas por adelantado), ya que estamos hablando de uno de los dos grandes conceptos que determinan si un test es o no adecuado. La fiabilidad, como sabeis, es algo fundamental que debemos conocer para valorar la calidad de un test , ahora bien, __no se calcula igual en todos los casos__, dependiendo de las condiciones y objetivos de cada instrumento de medida.\n",
    "\n",
    "En esta práctica, que se divide en tres, vamos a trabajar las siguientes situaciones:\n",
    "\n",
    "* 1. Cálculo de la Fiabilidad como __acuerdo entre jueces__ (kappa)\n",
    "* 2. Cálculo de la Fiabilidad como __consistencia temporal__\n",
    "    * 2.1. Método del Test - Retest\n",
    "    * 2.1. Método de los test Paralelos\n",
    "* 3. Cálculo de la Fiabilidad como __consistencia interna__\n",
    "    * 2.1. Método de las dos mitades\n",
    "    * 2.1. Método del alpha de Cronbach\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Cálculo de la Fiabilidad como acuerdo entre jueces (kappa)\n",
    "\n",
    "Kappa ($\\kappa$) nos informa del acuerdo que existe entre dos evaluadores a la hora de categorizar un conjunto de objetos, y ajusta el efecto del azar.\n",
    "\n",
    "Lo entederemos mejor con un ejemplo, imaginemos dos psicólogos diagnosticando a un grupo de pacientes en tres posibles trastornos: Ansiedad, Depresión y T.O.C. (Trastorno Obsesivo Compulsivo). Para cada paciente pueden ocurrir dos cosas, que los dos psicólogos coincidan en el diagnóstico o que no lo hagan. Cuando coinciden se dice que hay un acuerdo y cuando no lo hacen hay un desacuerdo.\n",
    "\n",
    "Kappa puede obtener valores entre 0 y 1. Cuanto más cercano a 1 sea el valor, mayor es el grado de concordancia entre los observadores, cuanto más cercano a 0, menor acuerdo entre ellos.\n",
    "\n",
    "La fórmula de Kappa es la siguiente:\n",
    "\n",
    "$$\\kappa =  \\frac{P_O - P_E}{1 - P_E}$$\n",
    "\n",
    "Siendo $P_O$: la proporción acuerdos y $P_E$ la proporción de acuerdos esperables al azar.\n",
    "\n",
    "En clase de teoría se explicará cómo calcular la fórmula _a mano_, pero en esta lección veremos cómo calcularlo con R. Primero vamos a importar unos datos ya preparados, para ello importa el fichero _kappa.csv_ (que también se encuentra en la carpeta datos) como hemos visto en lecciones anteriores\n",
    "\n",
    "__Ejercicio 1:__ Importa el fichero _kappa.csv_, guárdalo en el objeto _datos_ y visualízalo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce aquí el código (para ejecutarlo pulsa Ctr+Enter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puedes ver has obtenido dos variables, la primera se llama __E1__ y la segunda __E2__ indicando el Evaluador 1 y el 2. Las filas representan los objetos evaluados y los números en cada casilla representan la categoría asignada por cada evaluador. Por ejemplo, en la primera fila tenemos al primer paciente al que el evaluador 1 (E1) le ha asignado la categoría 2 y el evaluador 2 (E2) también le ha asignado la categoría 2, por lo que sería un acuerdo. Con el tercer paciente (fila 3) no habría acuerdo, ya que el primer evaluador le ha diagnosticado la categoría 3 y el segundo la categoría 2.\n",
    "\n",
    "Podemos crear una tabla con estos resultados usando lo aprendido en lecciones anteriores, usando la función _table()_\n",
    "\n",
    "__Ejercicio 2:__ Crea una tabla para el Evaluador 1 y el Evaluador 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce aquí el código (para ejecutarlo pulsa Ctr+Enter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Habrás obtenido una tabla como la siguiente:\n",
    "\n",
    "```\n",
    "     1  2  3  4  5\n",
    "  1 39  4  0  0  0\n",
    "  2  3 37  3  0  1\n",
    "  3  3  6 39  0  3\n",
    "  4  0  0  0 38  2\n",
    "  5  7  1  6  0 34\n",
    "```\n",
    "\n",
    "En la diagonal están los acuerdos (con 39 pacientes el evaluador 1 y el evaluador 2 han marcado la categoría 1) y fuera de ella los desacuerdos.\n",
    "\n",
    "Para calcular _Kappa_ con R primero tenemos que cargar una librería llamada _psych_, para ello tienes que introducir la siguiente sintaxis\n",
    "\n",
    "```R\n",
    "  library(psych)\n",
    "``` \n",
    "\n",
    "Al ejecutar esta sintaxis todas las funciones incluídas en _psych_ estarán disponibles para usarse, entre ellas la función _cohen.kappa()_ que calcula el índice de _Kappa_\n",
    "\n",
    "```R\n",
    "  cohen.kappa(datos)\n",
    "```\n",
    "\n",
    "__Ejercicio 3:__ Carga la librería _psych_ y con __datos__ calcula el índice de kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce aquí el código (para ejecutarlo pulsa Ctr+Enter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Habrás obtenido esta salida:\n",
    "\n",
    "```\n",
    "    Warning message:\n",
    "    \"package 'psych' was built under R version 3.4.4\"\n",
    "    Call: cohen.kappa1(x = x, w = w, n.obs = n.obs, alpha = alpha, levels = levels)\n",
    "\n",
    "    Cohen Kappa and Weighted Kappa correlation coefficients and confidence boundaries \n",
    "                     lower estimate upper\n",
    "    unweighted kappa  0.72     0.78  0.85\n",
    "    weighted kappa    0.69     0.78  0.88\n",
    "```\n",
    "\n",
    "No te preocupes por el Warning, es simplemente un aviso sobre compatibilidad de versiones. Lo que nos interesa son los siguientes valores:\n",
    "\n",
    "* El valor de _Kappa_ lo encontramos en la columna _estimate_ y la fila _unweighted kappa_ siendo 0.78\n",
    "* El intervalor de confianza para ese valor al 95% está entre 0.72 y 0.85\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Soluciones a los ejercicios:\n",
    "\n",
    "__Ejercicio 1:__\n",
    "```R\n",
    "    datos <- read.csv(file=\"datos/kappa.csv\", header=TRUE, sep=\";\", dec =\",\")\n",
    "    datos\n",
    "```\n",
    "\n",
    " __Ejercicio 2:__\n",
    "```\n",
    "    table(datos$E1, datos$E2)\n",
    "```\n",
    "\n",
    "__Ejercicio 3:__\n",
    "```R\n",
    "    library(psych)\n",
    "    cohen.kappa(datos)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<div align=\"right\">\n",
    "  Enero de 2019 |\n",
    "  <a href=\"autores.html\"> AUTORES <a>\n",
    "</div> \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
